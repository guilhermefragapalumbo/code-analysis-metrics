[
    {
        "Task Name": "Experiment Tracking",
        "Compliance Check": "Hyperparameter & Metric Logging",
        "Compliance description": "Check if the code logs hyperparameters, metrics, and model configurations for reproducibility."
    },
    {
        "Task Name": "Model Registry Management",
        "Compliance Check": "Version-Controlled Model Storage",
        "Compliance description": "Verify if the code stores models in a registry like MLflow or ModelDB for version control."
    },
    {
        "Task Name": "Performance Monitoring",
        "Compliance Check": "Model Performance Metric Tracking",
        "Compliance description": "Verify if the code logs key metrics like accuracy, latency, and throughput in production."
    },
    {
        "Task Name": "Data Drift Detection",
        "Compliance Check": "Input Data Distribution Monitoring",
        "Compliance description": "Check if the code includes mechanisms to track shifts in input data distribution."
    },
    {
        "Task Name": "Incident Response Planning",
        "Compliance Check": "Model Failure & Security Handling",
        "Compliance description": "Verify if the code includes strategies for handling failures, security threats, or biases."
    },
    {
        "Task Name": "Logging and Debugging",
        "Compliance Check": "Prediction & Failure Logging",
        "Compliance description": "Ensure the code maintains logs of predictions, failures, and user feedback for debugging."
    },
    {
        "Task Name": "Bias and Fairness Testing",
        "Compliance Check": "Bias Detection & Mitigation",
        "Compliance description": "Assess whether the code includes techniques to detect and mitigate model biases against specific groups."
    },
    {
        "Task Name": "Interpretability Analysis",
        "Compliance Check": "Model Explainability Implementation",
        "Compliance description": "Verify if the code uses SHAP, LIME, or feature importance scores to explain model predictions."
    }
]